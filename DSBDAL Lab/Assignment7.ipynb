{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c994e6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92fa0905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>link</th>\n",
       "      <th>domain</th>\n",
       "      <th>published_date</th>\n",
       "      <th>title</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.eurekalert.org/pub_releases/2020-0...</td>\n",
       "      <td>eurekalert.org</td>\n",
       "      <td>2020-08-06 13:59:45</td>\n",
       "      <td>closer look solar fuel potenti</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.pulse.ng/news/world/an-irresistibl...</td>\n",
       "      <td>pulse.ng</td>\n",
       "      <td>2020-08-12 15:14:19</td>\n",
       "      <td>irresist scent make locust swarm studi find</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.express.co.uk/news/science/1322607...</td>\n",
       "      <td>express.co.uk</td>\n",
       "      <td>2020-08-13 21:01:00</td>\n",
       "      <td>artifici intellig warn ai know us better know</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.ndtv.com/world-news/glaciers-could...</td>\n",
       "      <td>ndtv.com</td>\n",
       "      <td>2020-08-03 22:18:26</td>\n",
       "      <td>glacier could sculpt mar valley studi</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.thesun.ie/tech/5742187/perseid-met...</td>\n",
       "      <td>thesun.ie</td>\n",
       "      <td>2020-08-12 19:54:36</td>\n",
       "      <td>perseid meteor shower 2020 time see huge brigh...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic                                               link          domain  \\\n",
       "0  SCIENCE  https://www.eurekalert.org/pub_releases/2020-0...  eurekalert.org   \n",
       "1  SCIENCE  https://www.pulse.ng/news/world/an-irresistibl...        pulse.ng   \n",
       "2  SCIENCE  https://www.express.co.uk/news/science/1322607...   express.co.uk   \n",
       "3  SCIENCE  https://www.ndtv.com/world-news/glaciers-could...        ndtv.com   \n",
       "4  SCIENCE  https://www.thesun.ie/tech/5742187/perseid-met...       thesun.ie   \n",
       "\n",
       "        published_date                                              title lang  \n",
       "0  2020-08-06 13:59:45                     closer look solar fuel potenti   en  \n",
       "1  2020-08-12 15:14:19        irresist scent make locust swarm studi find   en  \n",
       "2  2020-08-13 21:01:00      artifici intellig warn ai know us better know   en  \n",
       "3  2020-08-03 22:18:26              glacier could sculpt mar valley studi   en  \n",
       "4  2020-08-12 19:54:36  perseid meteor shower 2020 time see huge brigh...   en  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"news_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "168300d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic             0\n",
       "link              0\n",
       "domain            0\n",
       "published_date    0\n",
       "title             0\n",
       "lang              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73b5f826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic             object\n",
       "link              object\n",
       "domain            object\n",
       "published_date    object\n",
       "title             object\n",
       "lang              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "202c486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['link', 'domain', 'published_date', 'lang'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adebdedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>closer look solar fuel potenti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>irresist scent make locust swarm studi find</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>artifici intellig warn ai know us better know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>glacier could sculpt mar valley studi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>perseid meteor shower 2020 time see huge brigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15769</th>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>mcdonald clarifi eat help scheme rule confus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15770</th>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>bewar harm product local store shelv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15771</th>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>yuan clear card transact enhanc renminbi inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15772</th>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>market trend latest pandem affect residenti re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15773</th>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>global high pressur cold water cleaner market ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15774 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          topic                                              title\n",
       "0       SCIENCE                     closer look solar fuel potenti\n",
       "1       SCIENCE        irresist scent make locust swarm studi find\n",
       "2       SCIENCE      artifici intellig warn ai know us better know\n",
       "3       SCIENCE              glacier could sculpt mar valley studi\n",
       "4       SCIENCE  perseid meteor shower 2020 time see huge brigh...\n",
       "...         ...                                                ...\n",
       "15769  BUSINESS       mcdonald clarifi eat help scheme rule confus\n",
       "15770  BUSINESS               bewar harm product local store shelv\n",
       "15771  BUSINESS  yuan clear card transact enhanc renminbi inter...\n",
       "15772  BUSINESS  market trend latest pandem affect residenti re...\n",
       "15773  BUSINESS  global high pressur cold water cleaner market ...\n",
       "\n",
       "[15774 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0020ce7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Soft\n",
      "[nltk_data]     Access\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d3f4137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['closer', 'look', 'solar', 'fuel', 'potenti']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(df['title'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9e56d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['closer look solar fuel potenti']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(df[\"title\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35c97508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Soft Access\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "words = nltk.word_tokenize(['title'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03c462e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('title', 'NN')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b1e4b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Soft\n",
      "[nltk_data]     Access\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "214c34c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "STOP_WORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9ffcf72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0ea0e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60049873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['irresist', 'scent', 'make', 'locust', 'swarm', 'studi', 'find']\n",
      "irresist\n",
      "scent\n",
      "make\n",
      "locust\n",
      "swarm\n",
      "studi\n",
      "find\n"
     ]
    }
   ],
   "source": [
    "arr = nltk.word_tokenize(df['title'][1])\n",
    "print(arr)\n",
    "for ele in arr:\n",
    "    print(ps.stem(ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae2683b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnetlemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c2c8ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Soft\n",
      "[nltk_data]     Access\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43a06f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Soft\n",
      "[nltk_data]     Access\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\omw-1.4.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a3006c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnetlemmatizer.lemmatize('runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e498efb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "464d1afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8db0c556",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SOFTAC~1\\AppData\\Local\\Temp/ipykernel_4152/1327608864.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "data = tfidf.fit_transform(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac92e5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d40904d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac56cf03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a5cf73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
